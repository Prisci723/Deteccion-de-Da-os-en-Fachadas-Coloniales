# -*- coding: utf-8 -*-
"""ProyectoSfmVariasImagenes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BbT-mufDnIPkPVY_uoI025aLN5vZgrLB
"""

import os
import numpy as np
import cv2
import matplotlib.pyplot as plt
from scipy.spatial.transform import Rotation
import networkx as nx
from scipy import ndimage
from skimage import exposure
import glob

def cargar_imagenes(folder_path):
    imagenes = []
    nombres = []
    for archivo in sorted(os.listdir(folder_path)):
        if archivo.lower().endswith(('.png', '.jpg', '.jpeg')):
            ruta = os.path.join(folder_path, archivo)
            img = cv2.imread(ruta)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convertir de BGR a RGB
            imagenes.append(img)
            nombres.append(archivo)
            print(f"Imagen cargada: {archivo}, forma: {img.shape}")
    return imagenes, nombres

def cargar_imagenes_desde_drive(ruta_carpeta):
    """
    Carga imágenes desde Google Drive
    """
    # Ruta completa a la carpeta de imágenes
    ruta_completa = os.path.join(ruta_carpeta)

    # Buscar todas las imágenes en la carpeta
    tipos_imagen = ['*.jpg', '*.jpeg', '*.png']
    rutas_imagenes = []

    for tipo in tipos_imagen:
        rutas_imagenes.extend(glob.glob(os.path.join(ruta_completa, tipo)))

    # Ordenar las imágenes para asegurar secuencia
    rutas_imagenes.sort()

    # Cargar las imágenes
    imagenes = []
    for ruta in rutas_imagenes:
        img = cv2.imread(ruta)
        if img is not None:
            # Convertir de BGR a RGB para visualización correcta
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            imagenes.append(img_rgb)
            print(f"Imagen cargada: {os.path.basename(ruta)}")
        else:
            print(f"No se pudo cargar la imagen: {ruta}")

    return imagenes, rutas_imagenes

def detectar_caracteristicas(imagenes):
    """
    Detecta puntos característicos usando SIFT en cada imagen
    """
    # Inicializar el detector SIFT
    sift = cv2.SIFT_create()

    # Almacenar keypoints y descriptores
    keypoints = []
    descriptores = []

    for img in imagenes:
        # Convertir a escala de grises para la detección de características
        gris = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)

        # Detectar keypoints y calcular descriptores
        kp, des = sift.detectAndCompute(gris, None)
        keypoints.append(kp)
        descriptores.append(des)

        print(f"Detectados {len(kp)} puntos en la imagen")

    return keypoints, descriptores

def encontrar_correspondencias(descriptores):
    """
    Encuentra correspondencias entre pares de imágenes consecutivas
    """
    # Usamos el matcher de fuerza bruta con norma L2 para SIFT
    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)

    # Almacenar todas las correspondencias
    todas_correspondencias = []
    buenos_matches = []

    # Encontrar correspondencias entre imágenes consecutivas
    for i in range(len(descriptores) - 1):
        # Usar knnMatch para permitir el ratio test
        matches = bf.knnMatch(descriptores[i], descriptores[i+1], k=2)

        # Aplicar el ratio test de Lowe para filtrar matches de calidad
        good = []
        for m, n in matches:
            if m.distance < 0.7 * n.distance:  # Ratio test
                good.append(m)

        todas_correspondencias.append(matches)
        buenos_matches.append(good)

        print(f"Par {i}-{i+1}: {len(good)} buenas correspondencias de {len(matches)} totales")

    return todas_correspondencias, buenos_matches

def estimar_homografias(keypoints, buenos_matches):
    """
    Estima las matrices de homografía entre pares de imágenes
    """
    homografias = []
    mascaras = []

    for i, matches in enumerate(buenos_matches):
        # Obtener los puntos correspondientes
        pts1 = np.float32([keypoints[i][m.queryIdx].pt for m in matches])
        pts2 = np.float32([keypoints[i+1][m.trainIdx].pt for m in matches])

        # Calcular la homografía usando RANSAC
        H, mask = cv2.findHomography(pts1, pts2, cv2.RANSAC, 5.0)
        homografias.append(H)
        mascaras.append(mask)

        inliers = np.sum(mask)
        print(f"Homografía {i}-{i+1}: {inliers} inliers de {len(matches)} correspondencias")

    return homografias, mascaras

def componer_homografias(homografias, imagenes):
    """
    Compone las homografías para transformar todas las imágenes al sistema de coordenadas de la primera
    """
    # La primera imagen permanece igual
    h_compuestas = [np.eye(3)]  # Matriz identidad para la primera imagen

    # Para cada par de imágenes, calcular la transformación acumulada
    h_acumulada = np.eye(3)
    for h in homografias:
        h_acumulada = h_acumulada @ np.linalg.inv(h)  # Composición de homografías
        h_compuestas.append(h_acumulada)

    return h_compuestas

def calcular_limites_panorama(imagenes, h_compuestas):
    """
    Calcula los límites del panorama final
    """
    altura, anchura = imagenes[0].shape[:2]

    # Puntos en las esquinas de cada imagen
    corners = np.array([
        [0, 0, 1],
        [0, altura-1, 1],
        [anchura-1, altura-1, 1],
        [anchura-1, 0, 1]
    ])

    # Transformar las esquinas de cada imagen al sistema de coordenadas de la primera
    corners_transformados = []
    for h in h_compuestas:
        # Multiplicar por la homografía
        transformed = np.dot(h, corners.T).T

        # Normalizar las coordenadas homogéneas
        transformed = transformed[:, :2] / transformed[:, 2:]
        corners_transformados.append(transformed)

    # Encontrar los límites del panorama
    all_corners = np.vstack(corners_transformados)
    x_min, y_min = np.min(all_corners, axis=0)
    x_max, y_max = np.max(all_corners, axis=0)

    return int(x_min), int(y_min), int(x_max), int(y_max)

def crear_mosaico(imagenes, h_compuestas, x_min, y_min, x_max, y_max):
    """
    Crea el mosaico final combinando todas las imágenes transformadas
    """
    # Calcular el tamaño del panorama
    ancho = x_max - x_min + 1
    alto = y_max - y_min + 1

    # Crear una matriz para el resultado
    resultado = np.zeros((alto, ancho, 3), dtype=np.uint8)

    # Matriz para rastrear qué píxeles ya se han llenado (ponderación)
    pesos = np.zeros((alto, ancho), dtype=np.float32)

    # Transformación para ajustar el offset
    offset = np.array([
        [1, 0, -x_min],
        [0, 1, -y_min],
        [0, 0, 1]
    ])

    for idx, img in enumerate(imagenes):
        # Combinar offset con la homografía compuesta
        h_final = offset @ h_compuestas[idx]

        # Transformar la imagen
        warped = cv2.warpPerspective(img, h_final, (ancho, alto))

        # Crear una máscara para los píxeles no negros
        mascara = np.sum(warped, axis=2) > 0

        # Actualizar el resultado con ponderación de distancia al centro
        altura, anchura = img.shape[:2]
        centro_y, centro_x = altura // 2, anchura // 2

        # Aplicar una ponderación gaussiana basada en la distancia al centro
        y, x = np.mgrid[:altura, :anchura]
        distancia_al_centro = np.sqrt((x - centro_x)**2 + (y - centro_y)**2)

        # Normalizar la distancia
        distancia_max = np.sqrt(centro_x**2 + centro_y**2)
        peso_normalizado = np.exp(-0.5 * (distancia_al_centro / distancia_max)**2)

        # Aplicar la transformación de perspectiva a la matriz de pesos
        warped_pesos = cv2.warpPerspective(peso_normalizado, h_final, (ancho, alto))

        # Actualizar las regiones del resultado donde la imagen actual tiene información
        for c in range(3):
            # Solo actualizar donde hay píxeles válidos y el peso es mayor que el existente
            actualizar = mascara & (warped_pesos > pesos)
            resultado[actualizar, c] = warped[actualizar, c]

        # Actualizar la matriz de pesos
        pesos = np.maximum(pesos, warped_pesos)

    return resultado

def analizar_danos(imagen_panorama):
    """
    Función simple para resaltar posibles daños en la fachada
    Esta es una implementación básica que se puede mejorar con métodos más avanzados
    """
    # Convertir a HSV para mejor análisis de color
    hsv = cv2.cvtColor(imagen_panorama, cv2.COLOR_RGB2HSV)

    # Detectar posibles áreas de humedad (tonos más oscuros/azulados)
    lower_humidity = np.array([90, 50, 50])
    upper_humidity = np.array([130, 255, 200])
    mascara_humedad = cv2.inRange(hsv, lower_humidity, upper_humidity)

    # Detectar posibles desprendimientos (diferencias de textura)
    gris = cv2.cvtColor(imagen_panorama, cv2.COLOR_RGB2GRAY)
    bordes = cv2.Canny(gris, 50, 150)

    # Dilatar los bordes para hacerlos más visibles
    kernel = np.ones((3, 3), np.uint8)
    bordes_dilatados = cv2.dilate(bordes, kernel, iterations=1)

    # Crear una imagen de visualización
    resultado_analisis = imagen_panorama.copy()

    # Marcar áreas de humedad en azul
    resultado_analisis[mascara_humedad > 0] = [0, 0, 255]  # Color azul para humedad

    # Marcar bordes/grietas en rojo
    resultado_analisis[bordes_dilatados > 0] = [255, 0, 0]  # Color rojo para grietas

    return resultado_analisis
